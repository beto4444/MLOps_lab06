{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8f7fc17",
   "metadata": {},
   "source": [
    "### 1. Data downloading and exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f139b074",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as snssa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac1bf3ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 10003\n",
      "Test size: 3080\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"banking77\")\n",
    "\n",
    "train = dataset[\"train\"]\n",
    "test = dataset[\"test\"]\n",
    "\n",
    "print(\"Train size:\", len(train))\n",
    "print(\"Test size:\", len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99a62425",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I am still waiting on my card?</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What can I do if my card still hasn't arrived ...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I have been waiting over a week. Is the card s...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Can I track my card while it is in the process...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How do I know if I will get my card, or if it ...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0                     I am still waiting on my card?     11\n",
       "1  What can I do if my card still hasn't arrived ...     11\n",
       "2  I have been waiting over a week. Is the card s...     11\n",
       "3  Can I track my card while it is in the process...     11\n",
       "4  How do I know if I will get my card, or if it ...     11"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = train.to_pandas()\n",
    "df_test = test.to_pandas()\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb2c814",
   "metadata": {},
   "source": [
    "#### 1.1. Data exploration - dtypes, dataset size, classes range etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6dbf736b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10003 entries, 0 to 10002\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    10003 non-null  object\n",
      " 1   label   10003 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 156.4+ KB\n",
      "None\n",
      "\n",
      "Test info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3080 entries, 0 to 3079\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    3080 non-null   object\n",
      " 1   label   3080 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 48.3+ KB\n",
      "None\n",
      "\n",
      "Sample labels: [11 13 32 17 34 46 36 12  4 14]\n",
      "Min label: 0\n",
      "Max label: 76\n"
     ]
    }
   ],
   "source": [
    "print(\"Train info:\")\n",
    "print(df_train.info())\n",
    "\n",
    "print(\"\\nTest info:\")\n",
    "print(df_test.info())\n",
    "\n",
    "print(\"\\nSample labels:\", df_train[\"label\"].unique()[:10])\n",
    "print(\"Min label:\", df_train[\"label\"].min())\n",
    "print(\"Max label:\", df_train[\"label\"].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe22d335",
   "metadata": {},
   "source": [
    "#### 1.2. Text lengths histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a202525b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_lengths = df_train[\"text\"].apply(lambda x: len(x.split()))\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.hist(train_lengths, bins=30)\n",
    "plt.title(\"Histogram of text lengths (train)\")\n",
    "plt.xlabel(\"Number of words\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ff54ca",
   "metadata": {},
   "source": [
    "#### 1.3. Class distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e2b015b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9208/1574729949.py:2: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.countplot(x=df_train[\"label\"], palette=\"viridis\")\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(14,6))\n",
    "sns.countplot(x=df_train[\"label\"], palette=\"viridis\")\n",
    "plt.title(\"Class distribution in Banking77 (train)\")\n",
    "plt.xlabel(\"Class label\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fce8b60a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average text length: 11.949415175447365\n",
      "Median text length: 10.0\n",
      "Max length: 79\n",
      "Min length: 2\n"
     ]
    }
   ],
   "source": [
    "print(\"Average text length:\", train_lengths.mean())\n",
    "print(\"Median text length:\", train_lengths.median())\n",
    "print(\"Max length:\", train_lengths.max())\n",
    "print(\"Min length:\", train_lengths.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaeb4429",
   "metadata": {},
   "source": [
    "### 2. Cleaning data w. Cleanlab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3cc6d9",
   "metadata": {},
   "source": [
    "#### 2.1. Model training and embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d56a4ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76b55e866238459e8e0193b9a4610845",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(10003, 384)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "texts_train = df_train[\"text\"].to_numpy()\n",
    "labels_train = df_train[\"label\"].to_numpy()\n",
    "\n",
    "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "emb_train = embedder.encode(texts_train, show_progress_bar=True, batch_size=64)\n",
    "emb_train = np.asarray(emb_train)\n",
    "emb_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a75b5be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/home/bstepniewski/Programowanie/MLOps/MLOps_lab06/.venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1908: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/home/bstepniewski/Programowanie/MLOps/MLOps_lab06/.venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1908: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/home/bstepniewski/Programowanie/MLOps/MLOps_lab06/.venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1908: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/home/bstepniewski/Programowanie/MLOps/MLOps_lab06/.venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1908: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/home/bstepniewski/Programowanie/MLOps/MLOps_lab06/.venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1908: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10003, 77)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "clf = LogisticRegressionCV(\n",
    "    Cs=10,\n",
    "    cv=5,\n",
    "    max_iter=2000,\n",
    "    multi_class=\"auto\",\n",
    "    class_weight=\"balanced\",\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "pred_probs = cross_val_predict(\n",
    "    clf,\n",
    "    emb_train,\n",
    "    labels_train,\n",
    "    cv=5,\n",
    "    method=\"predict_proba\",\n",
    "    n_jobs=-1,\n",
    ")\n",
    "pred_probs.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19dd2110",
   "metadata": {},
   "source": [
    "#### 2.2. Running DataLab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "84b75bf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding null issues ...\n",
      "Finding label issues ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding outlier issues ...\n",
      "Finding near_duplicate issues ...\n",
      "Finding non_iid issues ...\n",
      "Finding class_imbalance issues ...\n",
      "Finding underperforming_group issues ...\n",
      "\n",
      "Audit complete. 633 issues found in the dataset.\n",
      "Dataset Information: num_examples: 10003, num_classes: 77\n",
      "\n",
      "Here is a summary of various issues found in your data:\n",
      "\n",
      "    issue_type  num_issues\n",
      "near_duplicate         350\n",
      "         label         151\n",
      "       outlier         131\n",
      "       non_iid           1\n",
      "\n",
      "Learn about each issue: https://docs.cleanlab.ai/stable/cleanlab/datalab/guide/issue_type_description.html\n",
      "See which examples in your dataset exhibit each issue via: `datalab.get_issues(<ISSUE_NAME>)`\n",
      "\n",
      "Data indices corresponding to top examples of each issue are shown below.\n",
      "\n",
      "\n",
      "------------------ near_duplicate issues -------------------\n",
      "\n",
      "About this issue:\n",
      "\tA (near) duplicate issue refers to two or more examples in\n",
      "    a dataset that are extremely similar to each other, relative\n",
      "    to the rest of the dataset.  The examples flagged with this issue\n",
      "    may be exactly duplicated, or lie atypically close together when\n",
      "    represented as vectors (i.e. feature embeddings).\n",
      "    \n",
      "\n",
      "Number of examples with this issue: 350\n",
      "Overall dataset quality in terms of this issue: 0.5981\n",
      "\n",
      "Examples representing most severe instances of this issue:\n",
      "      is_near_duplicate_issue  near_duplicate_score near_duplicate_sets  distance_to_nearest_neighbor\n",
      "4915                     True                   0.0        [4903, 4839]                           0.0\n",
      "6965                     True                   0.0              [6910]                           0.0\n",
      "4594                     True                   0.0              [4595]                           0.0\n",
      "4595                     True                   0.0              [4594]                           0.0\n",
      "1724                     True                   0.0              [1710]                           0.0\n",
      "\n",
      "\n",
      "----------------------- label issues -----------------------\n",
      "\n",
      "About this issue:\n",
      "\tExamples whose given label is estimated to be potentially incorrect\n",
      "    (e.g. due to annotation error) are flagged as having label issues.\n",
      "    \n",
      "\n",
      "Number of examples with this issue: 151\n",
      "Overall dataset quality in terms of this issue: 0.9881\n",
      "\n",
      "Examples representing most severe instances of this issue:\n",
      "      is_label_issue  label_score  given_label  predicted_label\n",
      "4301           False     0.000040           62               61\n",
      "93              True     0.000047           11               14\n",
      "4428            True     0.000185           29               40\n",
      "2289           False     0.000205           60               58\n",
      "1490            True     0.000343           41               11\n",
      "\n",
      "\n",
      "---------------------- outlier issues ----------------------\n",
      "\n",
      "About this issue:\n",
      "\tExamples that are very different from the rest of the dataset \n",
      "    (i.e. potentially out-of-distribution or rare/anomalous instances).\n",
      "    \n",
      "\n",
      "Number of examples with this issue: 131\n",
      "Overall dataset quality in terms of this issue: 0.3810\n",
      "\n",
      "Examples representing most severe instances of this issue:\n",
      "      is_outlier_issue  outlier_score\n",
      "3107              True       0.005061\n",
      "4633              True       0.006303\n",
      "8802              True       0.007870\n",
      "4655              True       0.007935\n",
      "93                True       0.008737\n",
      "\n",
      "\n",
      "---------------------- non_iid issues ----------------------\n",
      "\n",
      "About this issue:\n",
      "\tWhether the dataset exhibits statistically significant\n",
      "    violations of the IID assumption like:\n",
      "    changepoints or shift, drift, autocorrelation, etc.\n",
      "    The specific violation considered is whether the\n",
      "    examples are ordered such that almost adjacent examples\n",
      "    tend to have more similar feature values.\n",
      "    \n",
      "\n",
      "Number of examples with this issue: 1\n",
      "Overall dataset quality in terms of this issue: 0.0000\n",
      "\n",
      "Examples representing most severe instances of this issue:\n",
      "      is_non_iid_issue  non_iid_score\n",
      "6544              True       0.487290\n",
      "8302             False       0.527508\n",
      "8337             False       0.529160\n",
      "8292             False       0.530119\n",
      "9034             False       0.533813\n",
      "\n",
      "Additional Information: \n",
      "p-value: 0.0\n"
     ]
    }
   ],
   "source": [
    "from cleanlab import Datalab\n",
    "\n",
    "data_dict = {\n",
    "    \"text\": texts_train,\n",
    "    \"label\": labels_train,\n",
    "}\n",
    "\n",
    "lab = Datalab(data_dict, label_name=\"label\", task=\"classification\")\n",
    "lab.find_issues(pred_probs=pred_probs, features=emb_train)\n",
    "issues = lab.get_issues()\n",
    "lab.report()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e644c2",
   "metadata": {},
   "source": [
    "#### 2.3. Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8d746799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: \n",
      "I put the wrong pin too many times and now it is blocked. Can you help me unblock it?\n",
      "\tDuplicates: ['I put the wrong pin too many times and now it is blocked. Can you help me unblock it?']\n",
      "Idxes: 1710, Near duplicate idxes: [1724]\n",
      "\n",
      "Text: \n",
      "I can't seem to be able to use my card\n",
      "\n",
      "\n",
      "\n",
      "\tDuplicates: [\"I can't seem to be able to use my card\"]\n",
      "Idxes: 1290, Near duplicate idxes: [1246]\n",
      "\n",
      "Text: I can't seem to be able to use my card\n",
      "\tDuplicates: [\"\\nI can't seem to be able to use my card\\n\\n\\n\"]\n",
      "Idxes: 1246, Near duplicate idxes: [1290]\n",
      "\n",
      "Text: Where can I withdraw money from?\n",
      "\tDuplicates: ['\\nWhere can I withdraw money from?']\n",
      "Idxes: 4594, Near duplicate idxes: [4595]\n",
      "\n",
      "Text: \n",
      "Where can I withdraw money from?\n",
      "\tDuplicates: ['Where can I withdraw money from?']\n",
      "Idxes: 4595, Near duplicate idxes: [4594]\n",
      "\n",
      "Text: How can I reset my passcode?\n",
      "\tDuplicates: ['How can i reset my passcode ?' 'How do I reset my passcode?']\n",
      "Idxes: 4903, Near duplicate idxes: [4915 4839]\n",
      "\n",
      "Text: How can i reset my passcode ?\n",
      "\tDuplicates: ['How can I reset my passcode?' 'How do I reset my passcode?']\n",
      "Idxes: 4915, Near duplicate idxes: [4903 4839]\n",
      "\n",
      "Text: I put the wrong pin too many times and now it is blocked. Can you help me unblock it?\n",
      "\tDuplicates: ['\\nI put the wrong pin too many times and now it is blocked. Can you help me unblock it?']\n",
      "Idxes: 1724, Near duplicate idxes: [1710]\n",
      "\n",
      "Text: Why do you keep declining my payment? I tried several times already with this card and it is just not working.\n",
      "\tDuplicates: ['Why do you keep declining my payment?I tried several times already with this card and it is just not working.'\n",
      " 'Why do you keep declining my payment?I tried several times with this card and it is just not working.']\n",
      "Idxes: 5922, Near duplicate idxes: [5930 5921]\n",
      "\n",
      "Text: Why do you keep declining my payment?I tried several times already with this card and it is just not working.\n",
      "\tDuplicates: ['Why do you keep declining my payment? I tried several times already with this card and it is just not working.'\n",
      " 'Why do you keep declining my payment?I tried several times with this card and it is just not working.']\n",
      "Idxes: 5930, Near duplicate idxes: [5922 5921]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "duplicate_issues = lab.get_issues(\"near_duplicate\")\n",
    "duplicate_issues = duplicate_issues[duplicate_issues[\"is_near_duplicate_issue\"]]\n",
    "duplicate_issues = duplicate_issues.sort_values(by=\"near_duplicate_score\")\n",
    "\n",
    "for idx, row in duplicate_issues.head(10).iterrows():\n",
    "    text = texts_train[idx]\n",
    "    neighbors = texts_train[row[\"near_duplicate_sets\"][:3]]\n",
    "    print(f\"Text: {text}\")\n",
    "    print(f\"\\tDuplicates: {neighbors}\")\n",
    "    print(f\"Idxes: {idx}, Near duplicate idxes: {row['near_duplicate_sets'][:3]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b5ea56be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I am still waiting on my card?</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What can I do if my card still hasn't arrived ...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I have been waiting over a week. Is the card s...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Can I track my card while it is in the process...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How do I know if I will get my card, or if it ...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>You provide support in what countries?</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>What countries are you supporting?</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>What countries are getting support?</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10001</th>\n",
       "      <td>Are cards available in the EU?</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10002</th>\n",
       "      <td>Which countries are represented?</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10003 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label\n",
       "0                         I am still waiting on my card?     11\n",
       "1      What can I do if my card still hasn't arrived ...     11\n",
       "2      I have been waiting over a week. Is the card s...     11\n",
       "3      Can I track my card while it is in the process...     11\n",
       "4      How do I know if I will get my card, or if it ...     11\n",
       "...                                                  ...    ...\n",
       "9998              You provide support in what countries?     24\n",
       "9999                  What countries are you supporting?     24\n",
       "10000                What countries are getting support?     24\n",
       "10001                     Are cards available in the EU?     24\n",
       "10002                   Which countries are represented?     24\n",
       "\n",
       "[10003 rows x 2 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"text_lower\"] = df_train[\"text\"].str.lower()\n",
    "df_deduplicated = df_train.drop_duplicates(subset=\"text_lower\")\n",
    "df_deduplicated = df_deduplicated.drop(columns=\"text_lower\")\n",
    "df_deduplicated = df_deduplicated.reset_index(drop=True)\n",
    "df_deduplicated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd70405",
   "metadata": {},
   "source": [
    "#### 2.4. Label Issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9ee89838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 label issues\n",
      "y_true 11, y_pred 14, text: WHAT IS THE SOLUTION OF THIS PROBLEM\n",
      "\n",
      "y_true 29, y_pred 40, text: i am not a premium customer but i want a virtual card, how do i get it\n",
      "\n",
      "y_true 41, y_pred 11, text: Can you tell me the status of my new card?\n",
      "\n",
      "y_true 27, y_pred 7, text: please help me with this transfer, for some reason i can't transfer to a cryptocurency account\n",
      "\n",
      "y_true 14, y_pred 49, text: Can I use app to reset PIN attempts?\n",
      "\n",
      "y_true 49, y_pred 38, text: Where do I find PIN for my card?\n",
      "\n",
      "y_true 47, y_pred 62, text: i put money on my card and i dont see it on the balance\n",
      "\n",
      "y_true 26, y_pred 14, text: Is my card actually working? It's the first time I tried using it\n",
      "\n",
      "y_true 65, y_pred 54, text: What currencies can I use to top up my account?\n",
      "\n",
      "y_true 5, y_pred 48, text: My transfer is pending too long.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "label_issues = lab.get_issues(\"label\")\n",
    "label_issues = label_issues[label_issues[\"is_label_issue\"]]\n",
    "label_issues = label_issues.sort_values(by=\"label_score\")\n",
    "\n",
    "top_label_issues_y_true = label_issues.head(10)[\"given_label\"]\n",
    "top_label_issues_y_pred = label_issues.head(10)[\"predicted_label\"]\n",
    "top_label_issues_idxs = label_issues.head(10).index\n",
    "top_label_issues_texts = texts_train[top_label_issues_idxs]\n",
    "\n",
    "print(\"Top 10 label issues\")\n",
    "for text, y_true, y_pred in zip(top_label_issues_texts, top_label_issues_y_true, top_label_issues_y_pred):\n",
    "    print(f\"y_true {y_true}, y_pred {y_pred}, text: {text}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "88f2b6f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I am still waiting on my card?</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What can I do if my card still hasn't arrived ...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I have been waiting over a week. Is the card s...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Can I track my card while it is in the process...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How do I know if I will get my card, or if it ...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>You provide support in what countries?</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>What countries are you supporting?</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>What countries are getting support?</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10001</th>\n",
       "      <td>Are cards available in the EU?</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10002</th>\n",
       "      <td>Which countries are represented?</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10003 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label\n",
       "0                         I am still waiting on my card?     11\n",
       "1      What can I do if my card still hasn't arrived ...     11\n",
       "2      I have been waiting over a week. Is the card s...     11\n",
       "3      Can I track my card while it is in the process...     11\n",
       "4      How do I know if I will get my card, or if it ...     11\n",
       "...                                                  ...    ...\n",
       "9998              You provide support in what countries?     24\n",
       "9999                  What countries are you supporting?     24\n",
       "10000                What countries are getting support?     24\n",
       "10001                     Are cards available in the EU?     24\n",
       "10002                   Which countries are represented?     24\n",
       "\n",
       "[10003 rows x 2 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make sure we don't get key errors - we removed some rows earlier during deduplication\n",
    "label_issues = label_issues[label_issues.index.isin(df_deduplicated.index)]\n",
    "\n",
    "idxs = label_issues.index.tolist()\n",
    "pred_labels = label_issues[\"predicted_label\"]\n",
    "\n",
    "df_fixed = df_deduplicated.copy()\n",
    "df_fixed.loc[idxs, \"label\"] = pred_labels\n",
    "df_fixed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8108e1e",
   "metadata": {},
   "source": [
    "#### 2.5. Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "eea8593d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 outlier issues\n",
      "Outlier score: 0.0051, text: WHAT IS THE ATMOSPHERE OF IT\n",
      "Outlier score: 0.0063, text: what is the word?\n",
      "Outlier score: 0.0079, text: What is this witdrawal\n",
      "Outlier score: 0.0079, text: what is the matter?\n",
      "Outlier score: 0.0087, text: WHAT IS THE SOLUTION OF THIS PROBLEM\n",
      "Outlier score: 0.0107, text: I prefer Mastecard.\n",
      "Outlier score: 0.0164, text: I have made 5 attempts to make a very standard survey, yet I can't get it to work. What is the problem? Is there an issue related to your system?\n",
      "Outlier score: 0.0167, text: WHAT IS THE MAIN REASON OF THIS PROBLEM\n",
      "Outlier score: 0.0168, text: WHAT IS THE REASON FOR THAT\n",
      "Outlier score: 0.0189, text: why was i chargged\n"
     ]
    }
   ],
   "source": [
    "outliers = lab.get_issues(\"outlier\")\n",
    "outliers = outliers[outliers[\"is_outlier_issue\"]]\n",
    "outliers = outliers.sort_values(by=\"outlier_score\")\n",
    "\n",
    "print(\"Top 10 outlier issues\")\n",
    "for idx, row in outliers.head(10).iterrows():\n",
    "    text = texts_train[idx]\n",
    "    score = row[\"outlier_score\"]\n",
    "    print(f\"Outlier score: {score:.4f}, text: {text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "84ef1ffb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I am still waiting on my card?</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What can I do if my card still hasn't arrived ...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I have been waiting over a week. Is the card s...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Can I track my card while it is in the process...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How do I know if I will get my card, or if it ...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9867</th>\n",
       "      <td>I just moved to the US how do I get a card?</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9868</th>\n",
       "      <td>You provide support in what countries?</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9869</th>\n",
       "      <td>What countries are you supporting?</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9870</th>\n",
       "      <td>What countries are getting support?</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9871</th>\n",
       "      <td>Are cards available in the EU?</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9872 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label\n",
       "0                        I am still waiting on my card?     11\n",
       "1     What can I do if my card still hasn't arrived ...     11\n",
       "2     I have been waiting over a week. Is the card s...     11\n",
       "3     Can I track my card while it is in the process...     11\n",
       "4     How do I know if I will get my card, or if it ...     11\n",
       "...                                                 ...    ...\n",
       "9867        I just moved to the US how do I get a card?     24\n",
       "9868             You provide support in what countries?     24\n",
       "9869                 What countries are you supporting?     24\n",
       "9870                What countries are getting support?     24\n",
       "9871                     Are cards available in the EU?     24\n",
       "\n",
       "[9872 rows x 2 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#removing outliers\n",
    "outlier_idxs = outliers.index.tolist()\n",
    "df_final = df_fixed.drop(index=outlier_idxs)\n",
    "df_final = df_final.reset_index(drop=True)\n",
    "df_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b242f371",
   "metadata": {},
   "source": [
    "#### 2.6. Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef8d5b3",
   "metadata": {},
   "source": [
    "### 3. Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6c4d38",
   "metadata": {},
   "source": [
    "#### 3.1. Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "831a9b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import Dataset, DatasetDict\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "valid_size = 0.2\n",
    "df_train_final, df_valid = train_test_split(df_final, test_size=valid_size, random_state=0, stratify=df_final[\"label\"])\n",
    "\n",
    "datasets_dict = DatasetDict()\n",
    "datasets_dict[\"train\"] = Dataset.from_pandas(df_train_final, split=\"train\")\n",
    "datasets_dict[\"valid\"] = Dataset.from_pandas(df_valid, split=\"valid\")\n",
    "datasets_dict[\"test\"] = Dataset.from_pandas(df_test, split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f6cfed46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcb9f63f51a3458a9db1ef5aab251926",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7897 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "726e7ccb234648a0881edea3c798a987",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1975 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b4cd2298ce04959a7d5e2fd7140a3f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3080 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import joblib\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-uncased\")\n",
    "\n",
    "\n",
    "def tokenize(examples: dict) -> dict:\n",
    "    encoded_examples = tokenizer(examples[\"text\"], padding=True, truncation=True)\n",
    "    encoded_examples[\"label\"] = torch.tensor(examples[\"label\"])\n",
    "    return encoded_examples\n",
    "\n",
    "\n",
    "num_cores = joblib.cpu_count(only_physical_cores=True)\n",
    "datasets_tokenized = datasets_dict.map(tokenize, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bf0a180f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from torch.nn.functional import softmax\n",
    "from transformers import AutoModelForSequenceClassification, EvalPrediction, Trainer, TrainingArguments\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# set determinism settings\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(0)\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed_all(0)\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert/distilbert-base-uncased\", num_labels=77)\n",
    "\n",
    "\n",
    "# freeze some weights to speed up training\n",
    "for param in model.distilbert.embeddings.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for param in model.distilbert.transformer.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred: EvalPrediction) -> dict:\n",
    "    y_true = eval_pred.label_ids.ravel()\n",
    "    logits = torch.from_numpy(eval_pred.predictions)\n",
    "    # y_pred_proba = np.argmax(softmax(logits, dim=1).numpy(), axis=1)\n",
    "    y_pred = torch.argmax(logits, dim=1).numpy()\n",
    "\n",
    "    f1 = f1_score(y_true, y_pred, average=\"macro\")\n",
    "    mcc = matthews_corrcoef(y_true, y_pred)\n",
    "\n",
    "    return {\n",
    "        \"f1_macro\": f1,\n",
    "        \"mcc\": mcc,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8b4b1fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"finetuned_hw_model\",\n",
    "    # change num_train_epochs depending on your hardware\n",
    "    # if lower, increase learning rate and decrease save_steps and eval_steps\n",
    "    learning_rate=1e-4,\n",
    "    num_train_epochs=5,\n",
    "    eval_strategy=\"steps\",\n",
    "    metric_for_best_model=\"f1_macro\",\n",
    "    save_steps=50,\n",
    "    eval_steps=50,\n",
    "    save_total_limit=1,\n",
    "    load_best_model_at_end=True,\n",
    "    seed=0,\n",
    "    data_seed=0,\n",
    "    fp16=True,  # comment this out if you have unsupported hardware\n",
    "    dataloader_num_workers=1,  # comment out if necessary\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e505b730",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='212' max='4940' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 212/4940 10:06 < 3:47:27, 0.35 it/s, Epoch 0.21/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1 Macro</th>\n",
       "      <th>Mcc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>No log</td>\n",
       "      <td>4.329951</td>\n",
       "      <td>0.000465</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>No log</td>\n",
       "      <td>4.328763</td>\n",
       "      <td>0.000465</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>No log</td>\n",
       "      <td>4.328673</td>\n",
       "      <td>0.000465</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>No log</td>\n",
       "      <td>4.327969</td>\n",
       "      <td>0.000465</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[60]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      1\u001b[39m trainer = Trainer(\n\u001b[32m      2\u001b[39m     model=model,\n\u001b[32m      3\u001b[39m     args=training_args,\n\u001b[32m   (...)\u001b[39m\u001b[32m      7\u001b[39m     compute_metrics=compute_metrics,\n\u001b[32m      8\u001b[39m )\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Programowanie/MLOps/MLOps_lab06/.venv/lib/python3.11/site-packages/transformers/trainer.py:2245\u001b[39m, in \u001b[36mTrainer.train\u001b[39m\u001b[34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[39m\n\u001b[32m   2243\u001b[39m         hf_hub_utils.enable_progress_bars()\n\u001b[32m   2244\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2245\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2246\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2247\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2248\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2249\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2250\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Programowanie/MLOps/MLOps_lab06/.venv/lib/python3.11/site-packages/transformers/trainer.py:2560\u001b[39m, in \u001b[36mTrainer._inner_training_loop\u001b[39m\u001b[34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[39m\n\u001b[32m   2553\u001b[39m context = (\n\u001b[32m   2554\u001b[39m     functools.partial(\u001b[38;5;28mself\u001b[39m.accelerator.no_sync, model=model)\n\u001b[32m   2555\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m i != \u001b[38;5;28mlen\u001b[39m(batch_samples) - \u001b[32m1\u001b[39m\n\u001b[32m   2556\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.accelerator.distributed_type != DistributedType.DEEPSPEED\n\u001b[32m   2557\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m contextlib.nullcontext\n\u001b[32m   2558\u001b[39m )\n\u001b[32m   2559\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[32m-> \u001b[39m\u001b[32m2560\u001b[39m     tr_loss_step = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2562\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   2563\u001b[39m     args.logging_nan_inf_filter\n\u001b[32m   2564\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[32m   2565\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m (torch.isnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch.isinf(tr_loss_step))\n\u001b[32m   2566\u001b[39m ):\n\u001b[32m   2567\u001b[39m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[32m   2568\u001b[39m     tr_loss = tr_loss + tr_loss / (\u001b[32m1\u001b[39m + \u001b[38;5;28mself\u001b[39m.state.global_step - \u001b[38;5;28mself\u001b[39m._globalstep_last_logged)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Programowanie/MLOps/MLOps_lab06/.venv/lib/python3.11/site-packages/transformers/trainer.py:3736\u001b[39m, in \u001b[36mTrainer.training_step\u001b[39m\u001b[34m(self, model, inputs, num_items_in_batch)\u001b[39m\n\u001b[32m   3733\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb.reduce_mean().detach().to(\u001b[38;5;28mself\u001b[39m.args.device)\n\u001b[32m   3735\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.compute_loss_context_manager():\n\u001b[32m-> \u001b[39m\u001b[32m3736\u001b[39m     loss = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3738\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m inputs\n\u001b[32m   3739\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   3740\u001b[39m     \u001b[38;5;28mself\u001b[39m.args.torch_empty_cache_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   3741\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.state.global_step % \u001b[38;5;28mself\u001b[39m.args.torch_empty_cache_steps == \u001b[32m0\u001b[39m\n\u001b[32m   3742\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Programowanie/MLOps/MLOps_lab06/.venv/lib/python3.11/site-packages/transformers/trainer.py:3801\u001b[39m, in \u001b[36mTrainer.compute_loss\u001b[39m\u001b[34m(self, model, inputs, return_outputs, num_items_in_batch)\u001b[39m\n\u001b[32m   3799\u001b[39m         loss_kwargs[\u001b[33m\"\u001b[39m\u001b[33mnum_items_in_batch\u001b[39m\u001b[33m\"\u001b[39m] = num_items_in_batch\n\u001b[32m   3800\u001b[39m     inputs = {**inputs, **loss_kwargs}\n\u001b[32m-> \u001b[39m\u001b[32m3801\u001b[39m outputs = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3802\u001b[39m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[32m   3803\u001b[39m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[32m   3804\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args.past_index >= \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Programowanie/MLOps/MLOps_lab06/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Programowanie/MLOps/MLOps_lab06/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Programowanie/MLOps/MLOps_lab06/.venv/lib/python3.11/site-packages/transformers/models/distilbert/modeling_distilbert.py:976\u001b[39m, in \u001b[36mDistilBertForSequenceClassification.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[39m\n\u001b[32m    968\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    969\u001b[39m \u001b[33;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[32m    970\u001b[39m \u001b[33;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[32m    971\u001b[39m \u001b[33;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[32m    972\u001b[39m \u001b[33;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[32m    973\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    974\u001b[39m return_dict = return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config.use_return_dict\n\u001b[32m--> \u001b[39m\u001b[32m976\u001b[39m distilbert_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdistilbert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    977\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    978\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    979\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    980\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    981\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    982\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    983\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    984\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    985\u001b[39m hidden_state = distilbert_output[\u001b[32m0\u001b[39m]  \u001b[38;5;66;03m# (bs, seq_len, dim)\u001b[39;00m\n\u001b[32m    986\u001b[39m pooled_output = hidden_state[:, \u001b[32m0\u001b[39m]  \u001b[38;5;66;03m# (bs, dim)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Programowanie/MLOps/MLOps_lab06/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Programowanie/MLOps/MLOps_lab06/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Programowanie/MLOps/MLOps_lab06/.venv/lib/python3.11/site-packages/transformers/models/distilbert/modeling_distilbert.py:796\u001b[39m, in \u001b[36mDistilBertModel.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[39m\n\u001b[32m    791\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._use_sdpa \u001b[38;5;129;01mand\u001b[39;00m head_mask_is_none \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m output_attentions:\n\u001b[32m    792\u001b[39m         attention_mask = _prepare_4d_attention_mask_for_sdpa(\n\u001b[32m    793\u001b[39m             attention_mask, embeddings.dtype, tgt_len=input_shape[\u001b[32m1\u001b[39m]\n\u001b[32m    794\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m796\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m=\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    801\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    803\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Programowanie/MLOps/MLOps_lab06/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Programowanie/MLOps/MLOps_lab06/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Programowanie/MLOps/MLOps_lab06/.venv/lib/python3.11/site-packages/transformers/models/distilbert/modeling_distilbert.py:549\u001b[39m, in \u001b[36mTransformer.forward\u001b[39m\u001b[34m(self, x, attn_mask, head_mask, output_attentions, output_hidden_states, return_dict)\u001b[39m\n\u001b[32m    541\u001b[39m     layer_outputs = \u001b[38;5;28mself\u001b[39m._gradient_checkpointing_func(\n\u001b[32m    542\u001b[39m         layer_module.\u001b[34m__call__\u001b[39m,\n\u001b[32m    543\u001b[39m         hidden_state,\n\u001b[32m   (...)\u001b[39m\u001b[32m    546\u001b[39m         output_attentions,\n\u001b[32m    547\u001b[39m     )\n\u001b[32m    548\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m549\u001b[39m     layer_outputs = \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    550\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhidden_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    551\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    552\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    553\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    554\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    556\u001b[39m hidden_state = layer_outputs[-\u001b[32m1\u001b[39m]\n\u001b[32m    558\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Programowanie/MLOps/MLOps_lab06/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Programowanie/MLOps/MLOps_lab06/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Programowanie/MLOps/MLOps_lab06/.venv/lib/python3.11/site-packages/transformers/models/distilbert/modeling_distilbert.py:493\u001b[39m, in \u001b[36mTransformerBlock.forward\u001b[39m\u001b[34m(self, x, attn_mask, head_mask, output_attentions)\u001b[39m\n\u001b[32m    490\u001b[39m sa_output = \u001b[38;5;28mself\u001b[39m.sa_layer_norm(sa_output + x)  \u001b[38;5;66;03m# (bs, seq_length, dim)\u001b[39;00m\n\u001b[32m    492\u001b[39m \u001b[38;5;66;03m# Feed Forward Network\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m493\u001b[39m ffn_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mffn\u001b[49m\u001b[43m(\u001b[49m\u001b[43msa_output\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# (bs, seq_length, dim)\u001b[39;00m\n\u001b[32m    494\u001b[39m ffn_output: torch.Tensor = \u001b[38;5;28mself\u001b[39m.output_layer_norm(ffn_output + sa_output)  \u001b[38;5;66;03m# (bs, seq_length, dim)\u001b[39;00m\n\u001b[32m    496\u001b[39m output = (ffn_output,)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Programowanie/MLOps/MLOps_lab06/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Programowanie/MLOps/MLOps_lab06/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Programowanie/MLOps/MLOps_lab06/.venv/lib/python3.11/site-packages/transformers/models/distilbert/modeling_distilbert.py:427\u001b[39m, in \u001b[36mFFN.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    426\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: torch.Tensor) -> torch.Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m427\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mapply_chunking_to_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mff_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mchunk_size_feed_forward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mseq_len_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Programowanie/MLOps/MLOps_lab06/.venv/lib/python3.11/site-packages/transformers/pytorch_utils.py:253\u001b[39m, in \u001b[36mapply_chunking_to_forward\u001b[39m\u001b[34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[39m\n\u001b[32m    250\u001b[39m     \u001b[38;5;66;03m# concatenate output at same dimension\u001b[39;00m\n\u001b[32m    251\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m torch.cat(output_chunks, dim=chunk_dim)\n\u001b[32m--> \u001b[39m\u001b[32m253\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43minput_tensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Programowanie/MLOps/MLOps_lab06/.venv/lib/python3.11/site-packages/transformers/models/distilbert/modeling_distilbert.py:433\u001b[39m, in \u001b[36mFFN.ff_chunk\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    431\u001b[39m x = \u001b[38;5;28mself\u001b[39m.activation(x)\n\u001b[32m    432\u001b[39m x = \u001b[38;5;28mself\u001b[39m.lin2(x)\n\u001b[32m--> \u001b[39m\u001b[32m433\u001b[39m x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    434\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Programowanie/MLOps/MLOps_lab06/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Programowanie/MLOps/MLOps_lab06/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Programowanie/MLOps/MLOps_lab06/.venv/lib/python3.11/site-packages/torch/nn/modules/dropout.py:70\u001b[39m, in \u001b[36mDropout.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m     69\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m---> \u001b[39m\u001b[32m70\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Programowanie/MLOps/MLOps_lab06/.venv/lib/python3.11/site-packages/torch/nn/functional.py:1425\u001b[39m, in \u001b[36mdropout\u001b[39m\u001b[34m(input, p, training, inplace)\u001b[39m\n\u001b[32m   1422\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m p < \u001b[32m0.0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m p > \u001b[32m1.0\u001b[39m:\n\u001b[32m   1423\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mdropout probability has to be between 0 and 1, but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mp\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m   1424\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[32m-> \u001b[39m\u001b[32m1425\u001b[39m     _VF.dropout_(\u001b[38;5;28minput\u001b[39m, p, training) \u001b[38;5;28;01mif\u001b[39;00m inplace \u001b[38;5;28;01melse\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1426\u001b[39m )\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=datasets_tokenized[\"train\"],\n",
    "    eval_dataset=datasets_tokenized[\"valid\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dfff7130",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.functional import softmax\n",
    "\n",
    "pred_output = trainer.predict(valid_tokenized)\n",
    "logits = torch.from_numpy(pred_output.predictions)\n",
    "\n",
    "y_pred_proba = softmax(logits, dim=1).numpy()            # (n_samples, 77)\n",
    "y_pred = np.argmax(y_pred_proba, axis=1)                 # (n_samples,)\n",
    "y_true = np.array(valid_df[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1345e1fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9274878654477069"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_f1 = f1_score(y_true, y_pred, average=\"macro\")\n",
    "final_f1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops-course-agh-lab-06",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
